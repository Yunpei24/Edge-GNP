# Edge-GNP: On-Device Graph Pruning for Communication-Efficient Federated Learning

## üìã Description

Edge-GNP est un projet de recherche combinant l'apprentissage f√©d√©r√© (Federated Learning) et l'√©lagage de graphes pour l'entra√Ænement distribu√© de r√©seaux de neurones graphiques (GNN) sur des terminaux √† ressources limit√©es.

**Auteur:** Votre Nom  
**Cours:** Algorithmics, Complexity, and Graph Algorithms

## üéØ Objectifs

L'objectif principal est d'apprendre les param√®tres **w** d'un GNN qui minimise la perte agr√©g√©e tout en respectant des contraintes de communication:

```
min_{w, {GÃÉ_i}} F(w)  s.c.  C_comm ‚â§ B
```

o√π:
- **w**: Param√®tres du GNN
- **GÃÉ_i**: Graphes √©lagu√©s des clients
- **F(w)**: Fonction de perte agr√©g√©e
- **C_comm**: Co√ªt de communication
- **B**: Budget de communication

## üìÅ Structure du Projet

```
Edge-GNP/
‚îú‚îÄ‚îÄ graph_pruning.py            # Algorithmes d'√©lagage de graphes
‚îú‚îÄ‚îÄ gnn_model.py                # Mod√®les GNN (GCN, GraphSAGE, GAT)
‚îú‚îÄ‚îÄ federated_learning.py       # Syst√®me d'apprentissage f√©d√©r√©
‚îú‚îÄ‚îÄ experiments.py              # Suite d'exp√©rimentations
‚îú‚îÄ‚îÄ requirements.txt            # D√©pendances Python
‚îú‚îÄ‚îÄ main.py                     # Script principal pour ex√©cuter les exp√©riences
‚îî‚îÄ‚îÄ README.md                   # Ce fichier
```

## üîß Installation

### 1. Cr√©er un environnement virtuel (recommand√©)

```bash
python -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
venv\Scripts\activate  # Windows
```

### 2. Installer les d√©pendances

```bash
pip install -r requirements.txt
```

### 3. Installer PyTorch Geometric

**Pour CPU:**
```bash
pip install torch-scatter torch-sparse -f https://data.pyg.org/whl/torch-2.0.0+cpu.html
```

**Pour GPU (CUDA 11.8):**
```bash
pip install torch-scatter torch-sparse -f https://data.pyg.org/whl/torch-2.0.0+cu118.html
```

## üöÄ Utilisation

### Activation de l'Environnement Virtuel

```bash
source venv/bin/activate  # Linux/Mac
# ou
venv\Scripts\activate  # Windows
```

### üß™ Commandes de Test Compl√®tes

#### 1. Test Rapide des Algorithmes d'√âlagage

```bash
python graph_pruning.py
```

**Ce que cela fait** :
- G√©n√®re un graphe de test (Karate Club, 34 n≈ìuds)
- Compare les 3 m√©thodes d'√©lagage (Greedy, Spectral, Modular)
- Affiche les m√©triques de performance
- G√©n√®re des visualisations dans `images/`

**Sortie attendue** :
```
=== Greedy Edge Pruning ===
Original edges: 78, Pruned edges: 54 (-30.8%)
Clustering preserved: 92.3%
Spectral distance: 0.145
Time: 0.023s

=== Spectral Sparsification ===
...
```

---

#### 2. Exp√©riences Centralis√©es sur Cora (Baseline + Pruning)

```bash
# Baseline (graphe original)
python experiments.py --mode centralized --dataset cora --pruning none --epochs 200

# Greedy MST Pruning
python experiments.py --mode centralized --dataset cora --pruning greedy --rate 0.5 --epochs 200

# Modular Twin-Aware Pruning
python experiments.py --mode centralized --dataset cora --pruning modular --rate 0.5 --epochs 200

# Spectral Pruning
python experiments.py --mode centralized --dataset cora --pruning spectral --rate 0.5 --epochs 200
```

**R√©sultats g√©n√©r√©s** :
- Graphes √©lagu√©s : `images/original.png`, `images/greedy_pruned.png`, `images/modular_pruned.png`
- M√©triques de performance sauvegard√©es dans les logs

---

#### 3. Exp√©riences F√©d√©r√©es (Comparaison de Toutes les M√©thodes)

```bash
# Lancer les 4 exp√©riences f√©d√©r√©es comparatives
python experiments.py --mode federated --dataset cora --clients 10 --rounds 20
```

**Ce que cela fait** :
- Partitionne Cora en 10 clients (IID)
- Lance 20 rounds de Federated Learning
- Compare 4 m√©thodes : Baseline, Greedy MST, Modular, Spectral
- G√©n√®re les graphiques comparatifs

**Graphiques g√©n√©r√©s** :
- `images/federated_comparison.png` (comparaison globale)
- `images/federated_baseline.png`
- `images/federated_greedy.png`
- `images/federated_modular.png`
- `images/federated_spectral.png`

**‚è±Ô∏è Temps d'ex√©cution estim√©** : ~5-10 minutes

---

#### 4. Exp√©riences Compl√®tes (Reproduire Tous les R√©sultats)

```bash
# Tout-en-un : centralis√© + f√©d√©r√© + visualisations
python main.py --dataset cora --model gcn --experiment all --epochs 200
```

**Ce que cela fait** :
1. ‚úÖ T√©l√©charge Cora (si n√©cessaire)
2. ‚úÖ Entra√Ænement centralis√© (Baseline)
3. ‚úÖ √âlagage et r√©-entra√Ænement (Greedy, Modular, Spectral)
4. ‚úÖ Simulation Federated Learning (10 clients, 20 rounds)
5. ‚úÖ G√©n√®re toutes les visualisations dans `images/`
6. ‚úÖ Sauvegarde les m√©triques dans `results/metrics.json`

**‚è±Ô∏è Temps d'ex√©cution total** : ~15-20 minutes

---

#### 5. Tests Unitaires (Validation du Code)

```bash
# Tester les algorithmes d'√©lagage
python -m pytest tests/test_pruning.py -v

# Tester les mod√®les GNN
python -m pytest tests/test_gnn.py -v

# Tester le syst√®me f√©d√©r√©
python -m pytest tests/test_federated.py -v

# Tous les tests
python -m pytest tests/ -v
```

---

#### 6. Commandes Avanc√©es

**Personnaliser les hyperparam√®tres** :

```bash
# Federated Learning avec param√®tres personnalis√©s
python experiments.py --mode federated \
    --dataset cora \
    --clients 20 \
    --rounds 50 \
    --local-epochs 10 \
    --pruning modular \
    --rate 0.3 \
    --prune-every 5
```

**Utiliser un autre mod√®le GNN** :

```bash
# GraphSAGE au lieu de GCN
python main.py --dataset cora --model sage --experiment all

# GAT (Graph Attention Network)
python main.py --dataset cora --model gat --experiment all
```

**Exp√©riences sur d'autres datasets** :

```bash
# CiteSeer
python main.py --dataset citeseer --model gcn --experiment all

# PubMed
python main.py --dataset pubmed --model gcn --experiment all
```

---

### üìä R√©sum√© des Commandes Essentielles

| Objectif | Commande | Temps |
|----------|----------|-------|
| **Test rapide** | `python graph_pruning.py` | ~30s |
| **Baseline Cora** | `python experiments.py --mode centralized --dataset cora --pruning none` | ~2 min |
| **FL Comparatif** | `python experiments.py --mode federated --dataset cora` | ~10 min |
| **Tout reproduire** | `python main.py --experiment all` | ~20 min |


## üìä Algorithmes Impl√©ment√©s

### 1. Greedy Edge Pruning (MST Backbone)

**Complexit√©:** O(m log m)

```python
pruner = GreedyEdgePruning(
    pruning_rate=0.3,
    importance_metric='betweenness'
)
G_pruned = pruner.prune(G)
```

Utilise une approche de type **Kruskal inverse** (MST) pour garantir la connectivit√© du graphe √©lagu√© tout en maximisant l'importance des ar√™tes conserv√©es.

### 2. Spectral Graph Sparsification (SGS)

**Complexit√©:** O(mkn¬≤) o√π k = nombre de valeurs propres

```python
pruner = SpectralGraphSparsification(
    pruning_rate=0.3,
    num_eigenvalues=10
)
G_pruned = pruner.prune(G)
```

Pr√©serve les valeurs propres dominantes du Laplacien normalis√©.

### 3. Modular Twin-Aware Pruning

**Complexit√©:** O(m log m)

```python
pruner = ModularAwarePruning(
    pruning_rate=0.3
)
G_pruned = pruner.prune(G)
```

Inspir√© par la **D√©composition Modulaire** (travaux de Michel Habib), cet algorithme identifie les **Jumeaux** (Twins) :
- **False Twins**: N(u) = N(v)
- **True Twins**: N[u] = N[v]

Il p√©nalise les ar√™tes redondantes associ√©es √† ces structures pour un √©lagage structurellement intelligent.

## üìà Mod√®les GNN

### Graph Convolutional Network (GCN)

```python
model = GCN(
    num_features=16,
    hidden_dim=64,
    num_classes=2,
    num_layers=2,
    dropout=0.5
)
```

**√âquation de propagation:**
```
H^(l+1) = œÉ(DÃÉ^(-1/2) √É DÃÉ^(-1/2) H^(l) W^(l))
```

### GraphSAGE

```python
model = GraphSAGE(
    num_features=16,
    hidden_dim=64,
    num_classes=2,
    aggregator='mean'  # 'mean', 'max', 'lstm'
)
```

### Graph Attention Network (GAT)

```python
model = GAT(
    num_features=16,
    hidden_dim=64,
    num_classes=2,
    num_heads=8
)
```

## üîÑ Apprentissage F√©d√©r√©

### Cr√©er des Clients

```python
from federated_learning import FederatedClient

client = FederatedClient(
    client_id=0,
    graph=G,
    node_features=X,
    labels=y,
    train_mask=train_mask,
    val_mask=val_mask,
    test_mask=test_mask,
    pruner=GreedyEdgePruning(pruning_rate=0.3)
)
```

### Lancer Edge-GNP

```python
from federated_learning import EdgeGNPFederated, FederatedServer

# Serveur
server = FederatedServer(model_config)

# Syst√®me f√©d√©r√©
edge_gnp = EdgeGNPFederated(
    clients=[client1, client2, client3],
    server=server,
    num_rounds=50,
    local_epochs=5,
    client_fraction=1.0,
    prune_every=5
)

# Entra√Ænement
history = edge_gnp.run()

# Visualisation
edge_gnp.plot_results(save_path='results.png')
```


## üß™ Exp√©rimentations et R√©sultats

### 1. Classification sur Cora (Centralis√©)

Nous avons compar√© les performances du GCN sur le graphe original et les graphes √©lagu√©s avec un taux d'√©lagage de ~50%.

| M√©thode | Taux d'√âlagage | Ar√™tes | Accuracy | Temps |
|---------|----------------|--------|----------|--------|
| **Original** | 0% | 5278 (100%) | **80.30%** | - |
| Modular (Twins) | ~49% | 2707 (51.3%) | 77.90% | 0.07s |
| Greedy (MST) | ~51% | 2600 (49.2%) | 76.50% | 0.12s |
| Spectral | ~51% | 2600 (49.2%) | 79.10% | 45.0s |

> **Observations Cl√©s**:
> - L'**√©lagage Spectral** offre la meilleure pr√©servation de la pr√©cision (~1% de perte) mais est **~400√ó plus lent**
> - L'approche **Modular Twin-Aware** offre le meilleur **compromis vitesse/pr√©cision** avec seulement 2.4% de perte
> - Le **Greedy MST** garantit la connectivit√© mais sacrifie l√©g√®rement plus de pr√©cision (3.8% de perte)

![Centralized Results](Edge-GNP/images/centralized_results.png)

### 2. Apprentissage F√©d√©r√© - Comparaison des M√©thodes

Simulation avec **10 clients** (partition IID du graphe Cora) sur **20 rounds** de communication.

#### Configuration Exp√©rimentale
- **Dataset**: Cora (2708 n≈ìuds, 5278 ar√™tes, 7 classes)
- **Mod√®le**: GCN (2 couches, 16 features ‚Üí 64 hidden ‚Üí 7 classes)
- **Clients**: 10 (partition al√©atoire IID)
- **Rounds**: 20
- **√âpoques locales**: 5
- **Taux d'√©lagage**: 50%
- **Fr√©quence d'√©lagage**: Tous les 5 rounds

#### R√©sultats Comparatifs

| M√©thode | Accuracy Finale | Co√ªt Comm. Moyen (par round) | R√©duction Structure |
|---------|-----------------|------------------------------|---------------------|
| **Baseline** (Sans √©lagage) | ~77% | 40 MB + 0.4 MB (structure) | 0% |
| **Greedy MST** | ~77% | 40 MB + 0.4 MB (structure) | ~0% * |
| **Modular Twin-Aware** | ~77% | 40 MB + 0.4 MB (structure) | ~0% * |
| **Spectral** | ~77% | 40 MB + 0.4 MB (structure) | ~0% * |

\* *Sur des partitions IID al√©atoires du graphe Cora, les sous-graphes sont d√©j√† tr√®s sparsifi√©s (~518 ar√™tes par client). La contrainte de connectivit√© limite la r√©duction suppl√©mentaire possible.*

#### Analyse des R√©sultats

![Federated Comparison](Edge-GNP/images/federated_comparison.png)

**Points Cl√©s**:
1. **Convergence Stable**: Toutes les m√©thodes d'√©lagage convergent vers une accuracy comparable (~77%) au centralis√©, d√©montrant la **robustesse** de l'apprentissage f√©d√©r√© avec √©lagage
2. **Limitation des Partitions IID**: Le partitionnement al√©atoire cr√©e des sous-graphes d√©j√† √©pars, limitant les gains de compression structurelle
3. **R√©silience du Mod√®le**: Malgr√© l'√©lagage agressif (50%), l'accuracy reste stable, confirmant que les GNN sont **tol√©rants √† la sparsification**

#### R√©sultats par M√©thode

##### Baseline (Sans √©lagage)
![Baseline](Edge-GNP/images/federated_baseline.png)
- Co√ªt structurel constant (~518 ar√™tes par round)
- R√©f√©rence pour les autres m√©thodes

##### Greedy MST
![Greedy](Edge-GNP/images/federated_greedy.png)
- Maintien du squelette via MST
- Sur des partitions d√©j√† sparses, le gain est limit√© par la contrainte de connectivit√© (n-1 ar√™tes minimum)

##### Modular Twin-Aware
![Modular](Edge-GNP/images/federated_modular.png)
- Fusion des jumeaux structurels
- Les "modules" (groupes de jumeaux) sont rares apr√®s partitionnement IID

##### Spectral Sparsification
![Spectral](Edge-GNP/images/federated_spectral.png)
- Pr√©servation spectrale du Laplacien
- Maintient les ar√™tes essentielles √† la diffusion d'information

### 3. Visualisation de l'√âlagage (Graphe Complet Cora)

Comparaison visuelle des structures de graphes √©lagu√©s :

| Original | Greedy (MST) | Modular (Twin-Aware) |
|----------|--------------|----------------------|
| ![Original](Edge-GNP/images/original.png) | ![Greedy](Edge-GNP/images/greedy_pruned.png) | ![Modular](Edge-GNP/images/modular_pruned.png) |
| 5278 ar√™tes | 2600 ar√™tes (-51%) | 2707 ar√™tes (-49%) |

### 4. Conclusions et Recommandations

#### Sc√©nario 1: IoT / Ressources Limit√©es
**Recommandation**: **Greedy MST** ou **Modular Twin-Aware**
- Complexit√© O(m log m) adapt√©e aux dispositifs contraints
- Temps de calcul n√©gligeable (<100ms)
- Trade-off acceptable accuracy/vitesse

#### Sc√©nario 2: Applications Critiques
**Recommandation**: **Spectral Sparsification**
- Garanties th√©oriques (Œµ-sparsifier)
- Meilleure pr√©servation de l'accuracy
- Acceptable si le temps de calcul n'est pas critique

#### Sc√©nario 3: R√©seaux Sociaux / Communaut√©s
**Recommandation**: **Modular Twin-Aware**
- Exploite la structure modulaire naturelle
- D√©tection intelligente de la redondance
- Rapide et efficace

#### Pour le Federated Learning
- **Partitionnement par Communaut√©** (plut√¥t qu'IID) recommand√© pour maximiser les gains de compression
- Le co√ªt du mod√®le GNN (40 MB) domine largement le co√ªt structurel (0.4 MB)
- La **quantization des param√®tres** serait compl√©mentaire pour r√©duire davantage la communication


## üîç Analyse de Complexit√©

| Algorithme | Complexit√© Temps | Complexit√© Espace |
|------------|------------------|-------------------|
| Greedy (MST Backbone) | O(m log m) | O(n + m) |
| Spectral Sparsification | O(mkn¬≤) | O(n¬≤) |
| Modular/Twin-Aware | O(m log m) | O(n + m) |
| Edge-GNP (par round) | O(N¬∑m log m + N¬∑E¬∑T_GNN) | O(Np) |

o√π:
- **œÅ**: Taux d'√©lagage
- **m**: Nombre d'ar√™tes
- **n**: Nombre de n≈ìuds
- **k**: Nombre de valeurs propres
- **N**: Nombre de clients
- **E**: √âpoques locales
- **p**: Nombre de param√®tres du mod√®le


## üõ†Ô∏è D√©veloppement Futur

- [ ] √âlagage dynamique adaptatif
- [ ] Pruning diff√©rentiel pour confidentialit√©
- [ ] Support pour graphes h√©t√©rog√®nes
- [ ] Optimisation multi-objectifs
- [ ] Compression des param√®tres GNN
- [ ] Benchmark sur datasets r√©els (Cora, CiteSeer, PubMed)

## üìß Contact

Pour toute question sur le projet:
- **Email:** [Joshua.YUN-PEI@um6p.ma]
- **GitHub:** https://github.com/Yunpei24/Edge-GNP.git

## üìú Licence

Ce projet est d√©velopp√© dans un cadre acad√©mique pour le cours "Algorithmics, Complexity, and Graph Algorithms".

## üôè Remerciements

- Professeur du cours Professeur √©m√©rite Michel Habib pour les orientations
- Communaut√© PyTorch Geometric pour les outils GNN
- Travaux de recherche de McMahan et al. (FedAvg), Kipf & Welling (GCN)

---

**Note:** Ce projet est un prototype de recherche. Pour une utilisation en production, des optimisations suppl√©mentaires et des tests de robustesse sont n√©cessaires.
