# Edge-GNP: On-Device Graph Pruning for Communication-Efficient Federated Learning

## ğŸ“‹ Description

Edge-GNP est un projet de recherche combinant l'apprentissage fÃ©dÃ©rÃ© (Federated Learning) et l'Ã©lagage de graphes pour l'entraÃ®nement distribuÃ© de rÃ©seaux de neurones graphiques (GNN) sur des terminaux Ã  ressources limitÃ©es.

**Auteur:** Votre Nom  
**Cours:** Algorithmics, Complexity, and Graph Algorithms

## ğŸ¯ Objectifs

L'objectif principal est d'apprendre les paramÃ¨tres **w** d'un GNN qui minimise la perte agrÃ©gÃ©e tout en respectant des contraintes de communication:

```
min_{w, {GÌƒ_i}} F(w)  s.c.  C_comm â‰¤ B
```

oÃ¹:
- **w**: ParamÃ¨tres du GNN
- **GÌƒ_i**: Graphes Ã©laguÃ©s des clients
- **F(w)**: Fonction de perte agrÃ©gÃ©e
- **C_comm**: CoÃ»t de communication
- **B**: Budget de communication

## ğŸ“ Structure du Projet

```
Edge-GNP/
â”œâ”€â”€ graph_pruning.py            # Algorithmes d'Ã©lagage de graphes
â”œâ”€â”€ gnn_model.py                # ModÃ¨les GNN (GCN, GraphSAGE, GAT)
â”œâ”€â”€ federated_learning.py       # SystÃ¨me d'apprentissage fÃ©dÃ©rÃ©
â”œâ”€â”€ experiments.py              # Suite d'expÃ©rimentations
â”œâ”€â”€ requirements.txt            # DÃ©pendances Python
â”œâ”€â”€ main.py                     # Script principal pour exÃ©cuter les expÃ©riences
â””â”€â”€ README.md                   # Ce fichier
```

## ğŸ”§ Installation

### 1. CrÃ©er un environnement virtuel (recommandÃ©)

```bash
python -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
venv\Scripts\activate  # Windows
```

### 2. Installer les dÃ©pendances

```bash
pip install -r requirements.txt
```

### 3. Installer PyTorch Geometric

**Pour CPU:**
```bash
pip install torch-scatter torch-sparse -f https://data.pyg.org/whl/torch-2.0.0+cpu.html
```

**Pour GPU (CUDA 11.8):**
```bash
pip install torch-scatter torch-sparse -f https://data.pyg.org/whl/torch-2.0.0+cu118.html
```

## ğŸš€ Utilisation

### Test des Algorithmes d'Ã‰lagage

```python
python graph_pruning.py
```

Ce script:
- GÃ©nÃ¨re un graphe de test (Karate Club)
- Compare les 3 mÃ©thodes d'Ã©lagage:
  1. **Greedy Edge Pruning (MST Backbone)**: Ã‰lagage glouton avec garantie de connectivitÃ©
  2. **Spectral Sparsification**: PrÃ©servation du spectre du Laplacien
  3. **Modular Twin-Aware Pruning**: Ã‰lagage basÃ© sur la dÃ©composition modulaire (Habib)

### Test du GNN

```python
python gnn_model.py
```

EntraÃ®ne et Ã©value diffÃ©rents types de GNN:
- **GCN** (Graph Convolutional Network)
- **GraphSAGE**
- **GAT** (Graph Attention Network)

### Apprentissage FÃ©dÃ©rÃ©

```python
python federated_learning.py
```

Simule un systÃ¨me d'apprentissage fÃ©dÃ©rÃ© avec:
- Plusieurs clients avec graphes locaux
- Ã‰lagage pÃ©riodique des graphes
- AgrÃ©gation FedAvg
- MÃ©triques de performance et communication

### Suite d'ExpÃ©rimentations ComplÃ¨te (Benchmark)

Pour reproduire les rÃ©sultats sur Cora :

```bash
python main.py --dataset cora --model gcn --experiment all --epochs 200
```

Cela va :
1. TÃ©lÃ©charger le dataset Cora
2. EntraÃ®ner un GCN sur le graphe original (Baseline)
3. Ã‰lague le graphe avec l'approche Modulaire et rÃ©-entraÃ®ner
4. Lancer une simulation d'apprentissage fÃ©dÃ©rÃ© (10 clients)
5. GÃ©nÃ©rer les courbes de rÃ©sultats dans `Edge-GNP/images/`

## ğŸ“Š Algorithmes ImplÃ©mentÃ©s

### 1. Greedy Edge Pruning (MST Backbone)

**ComplexitÃ©:** O(m log m)

```python
pruner = GreedyEdgePruning(
    pruning_rate=0.3,
    importance_metric='betweenness'
)
G_pruned = pruner.prune(G)
```

Utilise une approche de type **Kruskal inverse** (MST) pour garantir la connectivitÃ© du graphe Ã©laguÃ© tout en maximisant l'importance des arÃªtes conservÃ©es.

### 2. Spectral Graph Sparsification (SGS)

**ComplexitÃ©:** O(mknÂ²) oÃ¹ k = nombre de valeurs propres

```python
pruner = SpectralGraphSparsification(
    pruning_rate=0.3,
    num_eigenvalues=10
)
G_pruned = pruner.prune(G)
```

PrÃ©serve les valeurs propres dominantes du Laplacien normalisÃ©.

### 3. Modular Twin-Aware Pruning

**ComplexitÃ©:** O(m log m)

```python
pruner = ModularAwarePruning(
    pruning_rate=0.3
)
G_pruned = pruner.prune(G)
```

InspirÃ© par la **DÃ©composition Modulaire** (travaux de Michel Habib), cet algorithme identifie les **Jumeaux** (Twins) :
- **False Twins**: N(u) = N(v)
- **True Twins**: N[u] = N[v]

Il pÃ©nalise les arÃªtes redondantes associÃ©es Ã  ces structures pour un Ã©lagage structurellement intelligent.

## ğŸ“ˆ ModÃ¨les GNN

### Graph Convolutional Network (GCN)

```python
model = GCN(
    num_features=16,
    hidden_dim=64,
    num_classes=2,
    num_layers=2,
    dropout=0.5
)
```

**Ã‰quation de propagation:**
```
H^(l+1) = Ïƒ(DÌƒ^(-1/2) Ãƒ DÌƒ^(-1/2) H^(l) W^(l))
```

### GraphSAGE

```python
model = GraphSAGE(
    num_features=16,
    hidden_dim=64,
    num_classes=2,
    aggregator='mean'  # 'mean', 'max', 'lstm'
)
```

### Graph Attention Network (GAT)

```python
model = GAT(
    num_features=16,
    hidden_dim=64,
    num_classes=2,
    num_heads=8
)
```

## ğŸ”„ Apprentissage FÃ©dÃ©rÃ©

### CrÃ©er des Clients

```python
from federated_learning import FederatedClient

client = FederatedClient(
    client_id=0,
    graph=G,
    node_features=X,
    labels=y,
    train_mask=train_mask,
    val_mask=val_mask,
    test_mask=test_mask,
    pruner=GreedyEdgePruning(pruning_rate=0.3)
)
```

### Lancer Edge-GNP

```python
from federated_learning import EdgeGNPFederated, FederatedServer

# Serveur
server = FederatedServer(model_config)

# SystÃ¨me fÃ©dÃ©rÃ©
edge_gnp = EdgeGNPFederated(
    clients=[client1, client2, client3],
    server=server,
    num_rounds=50,
    local_epochs=5,
    client_fraction=1.0,
    prune_every=5
)

# EntraÃ®nement
history = edge_gnp.run()

# Visualisation
edge_gnp.plot_results(save_path='results.png')
```


## ğŸ§ª ExpÃ©rimentations et RÃ©sultats

### 1. Classification sur Cora (CentralisÃ©)

Nous avons comparÃ© les performances du GCN sur le graphe original et les graphes Ã©laguÃ©s.

| MÃ©thode | Taux d'Ã‰lagage | ArÃªtes | Accuracy |
|---------|----------------|--------|----------|
| Original | 0% | 100% (5278) | **80.30%** |
| Modular (Twins) | ~50% | 51.3% (2707) | 77.90% |

> **Observation**: L'Ã©lagage modulaire rÃ©duit le graphe de moitiÃ© tout en conservant une prÃ©cision trÃ¨s proche de la baseline.

![Centralized Results](Edge-GNP/images/centralized_results.png)

### 2. Apprentissage FÃ©dÃ©rÃ©

Simulation avec 10 clients (partition IID du graphe Cora).

- **Convergence**: 50 rounds
- **EfficacitÃ©**: Le modÃ¨le apprend efficacement malgrÃ© la sparsification locale continue (Modular Twin-Aware Pruning).

![Federated Results](Edge-GNP/images/federated_results.png)

### 3. Visualisation de l'Ã‰lagage

Comparaison visuelle des structures de graphes :

| Original | Modular Pruned |
|----------|----------------|
| ![Original](Edge-GNP/images/original.png) | ![Modular](Edge-GNP/images/modular_pruned.png) |

## ğŸ” Analyse de ComplexitÃ©

| Algorithme | ComplexitÃ© Temps | ComplexitÃ© Espace |
|------------|------------------|-------------------|
| Greedy (MST Backbone) | O(m log m) | O(n + m) |
| Spectral Sparsification | O(mknÂ²) | O(nÂ²) |
| Modular/Twin-Aware | O(m log m) | O(n + m) |
| Edge-GNP (par round) | O(NÂ·m log m + NÂ·EÂ·T_GNN) | O(Np) |

oÃ¹:
- **Ï**: Taux d'Ã©lagage
- **m**: Nombre d'arÃªtes
- **n**: Nombre de nÅ“uds
- **k**: Nombre de valeurs propres
- **N**: Nombre de clients
- **E**: Ã‰poques locales
- **p**: Nombre de paramÃ¨tres du modÃ¨le


## ğŸ› ï¸ DÃ©veloppement Futur

- [ ] Ã‰lagage dynamique adaptatif
- [ ] Pruning diffÃ©rentiel pour confidentialitÃ©
- [ ] Support pour graphes hÃ©tÃ©rogÃ¨nes
- [ ] Optimisation multi-objectifs
- [ ] Compression des paramÃ¨tres GNN
- [ ] Benchmark sur datasets rÃ©els (Cora, CiteSeer, PubMed)

## ğŸ“§ Contact

Pour toute question sur le projet:
- **Email:** [Joshua.YUN-PEI@um6p.ma]
- **GitHub:** https://github.com/Yunpei24/Edge-GNP.git

## ğŸ“œ Licence

Ce projet est dÃ©veloppÃ© dans un cadre acadÃ©mique pour le cours "Algorithmics, Complexity, and Graph Algorithms".

## ğŸ™ Remerciements

- Professeur du cours Professeur Emerite Michel Habib pour les orientations
- CommunautÃ© PyTorch Geometric pour les outils GNN
- Travaux de recherche de McMahan et al. (FedAvg), Kipf & Welling (GCN)

---

**Note:** Ce projet est un prototype de recherche. Pour une utilisation en production, des optimisations supplÃ©mentaires et des tests de robustesse sont nÃ©cessaires.
