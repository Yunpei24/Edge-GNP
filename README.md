# Edge-GNP: On-Device Graph Pruning for Communication-Efficient Federated Learning

## ğŸ“‹ Description

Edge-GNP est un projet de recherche combinant l'apprentissage fÃ©dÃ©rÃ© (Federated Learning) et l'Ã©lagage de graphes pour l'entraÃ®nement distribuÃ© de rÃ©seaux de neurones graphiques (GNN) sur des terminaux Ã  ressources limitÃ©es.

**Auteur:** Votre Nom  
**Cours:** Algorithmics, Complexity, and Graph Algorithms

## ğŸ¯ Objectifs

L'objectif principal est d'apprendre les paramÃ¨tres **w** d'un GNN qui minimise la perte agrÃ©gÃ©e tout en respectant des contraintes de communication:

```
min_{w, {GÌƒ_i}} F(w)  s.c.  C_comm â‰¤ B
```

oÃ¹:
- **w**: ParamÃ¨tres du GNN
- **GÌƒ_i**: Graphes Ã©laguÃ©s des clients
- **F(w)**: Fonction de perte agrÃ©gÃ©e
- **C_comm**: CoÃ»t de communication
- **B**: Budget de communication

## ğŸ“ Structure du Projet

```
Edge-GNP/
â”œâ”€â”€ graph_pruning.py            # Algorithmes d'Ã©lagage de graphes
â”œâ”€â”€ gnn_model.py                # ModÃ¨les GNN (GCN, GraphSAGE, GAT)
â”œâ”€â”€ federated_learning.py       # SystÃ¨me d'apprentissage fÃ©dÃ©rÃ©
â”œâ”€â”€ experiments.py              # Suite d'expÃ©rimentations
â”œâ”€â”€ requirements.txt            # DÃ©pendances Python
â””â”€â”€ README.md                   # Ce fichier
```

## ğŸ”§ Installation

### 1. CrÃ©er un environnement virtuel (recommandÃ©)

```bash
python -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
venv\Scripts\activate  # Windows
```

### 2. Installer les dÃ©pendances

```bash
pip install -r requirements.txt
```

### 3. Installer PyTorch Geometric

**Pour CPU:**
```bash
pip install torch-scatter torch-sparse -f https://data.pyg.org/whl/torch-2.0.0+cpu.html
```

**Pour GPU (CUDA 11.8):**
```bash
pip install torch-scatter torch-sparse -f https://data.pyg.org/whl/torch-2.0.0+cu118.html
```

## ğŸš€ Utilisation

### Test des Algorithmes d'Ã‰lagage

```python
python graph_pruning.py
```

Ce script:
- GÃ©nÃ¨re un graphe de test (Karate Club)
- Compare les 3 mÃ©thodes d'Ã©lagage:
  1. **Greedy Edge Pruning**: Ã‰lagage glouton basÃ© sur l'importance
  2. **Spectral Sparsification**: PrÃ©servation du spectre du Laplacien
  3. **Community-Aware Pruning**: PrÃ©servation de la structure communautaire

### Test du GNN

```python
python gnn_model.py
```

EntraÃ®ne et Ã©value diffÃ©rents types de GNN:
- **GCN** (Graph Convolutional Network)
- **GraphSAGE**
- **GAT** (Graph Attention Network)

### Apprentissage FÃ©dÃ©rÃ©

```python
python federated_learning.py
```

Simule un systÃ¨me d'apprentissage fÃ©dÃ©rÃ© avec:
- Plusieurs clients avec graphes locaux
- Ã‰lagage pÃ©riodique des graphes
- AgrÃ©gation FedAvg
- MÃ©triques de performance et communication

### Suite d'ExpÃ©rimentations ComplÃ¨te

```python
python experiments.py
```

ExÃ©cute 3 expÃ©riences:
1. **Impact du taux d'Ã©lagage**: Ã‰value l'effet de Ï âˆˆ [0.1, 0.5]
2. **Comparaison d'algorithmes**: Compare les 3 mÃ©thodes d'Ã©lagage
3. **Apprentissage fÃ©dÃ©rÃ©**: Teste diffÃ©rents taux d'Ã©lagage en FL

## ğŸ“Š Algorithmes ImplÃ©mentÃ©s

### 1. Greedy Edge Pruning (GEP)

**ComplexitÃ©:** O(ÏmÂ² + Ïmn)

```python
pruner = GreedyEdgePruning(
    pruning_rate=0.3,
    importance_metric='betweenness'  # 'betweenness', 'similarity', 'degree'
)
G_pruned = pruner.prune(G)
```

**MÃ©triques d'importance:**
- **Betweenness Centrality**: BC(e) = Î£ Ïƒ_st(e)/Ïƒ_st
- **Jaccard Similarity**: Sim(u,v) = |N(u)âˆ©N(v)|/|N(u)âˆªN(v)|
- **Degree Product**: I(u,v) = deg(u) Ã— deg(v)

### 2. Spectral Graph Sparsification (SGS)

**ComplexitÃ©:** O(mknÂ²) oÃ¹ k = nombre de valeurs propres

```python
pruner = SpectralGraphSparsification(
    pruning_rate=0.3,
    num_eigenvalues=10
)
G_pruned = pruner.prune(G)
```

PrÃ©serve les valeurs propres dominantes du Laplacien normalisÃ©.

### 3. Community-Aware Pruning (CAP)

**ComplexitÃ©:** O(m log m) avec dÃ©tection Louvain

```python
pruner = CommunityAwarePruning(
    pruning_rate=0.3,
    preserve_intra=True
)
G_pruned = pruner.prune(G)
```

DÃ©tecte les communautÃ©s et prÃ©serve prioritairement les arÃªtes intra-communautÃ©.

## ğŸ“ˆ ModÃ¨les GNN

### Graph Convolutional Network (GCN)

```python
model = GCN(
    num_features=16,
    hidden_dim=64,
    num_classes=2,
    num_layers=2,
    dropout=0.5
)
```

**Ã‰quation de propagation:**
```
H^(l+1) = Ïƒ(DÌƒ^(-1/2) Ãƒ DÌƒ^(-1/2) H^(l) W^(l))
```

### GraphSAGE

```python
model = GraphSAGE(
    num_features=16,
    hidden_dim=64,
    num_classes=2,
    aggregator='mean'  # 'mean', 'max', 'lstm'
)
```

### Graph Attention Network (GAT)

```python
model = GAT(
    num_features=16,
    hidden_dim=64,
    num_classes=2,
    num_heads=8
)
```

## ğŸ”„ Apprentissage FÃ©dÃ©rÃ©

### CrÃ©er des Clients

```python
from federated_learning import FederatedClient

client = FederatedClient(
    client_id=0,
    graph=G,
    node_features=X,
    labels=y,
    train_mask=train_mask,
    val_mask=val_mask,
    test_mask=test_mask,
    pruner=GreedyEdgePruning(pruning_rate=0.3)
)
```

### Lancer Edge-GNP

```python
from federated_learning import EdgeGNPFederated, FederatedServer

# Serveur
server = FederatedServer(model_config)

# SystÃ¨me fÃ©dÃ©rÃ©
edge_gnp = EdgeGNPFederated(
    clients=[client1, client2, client3],
    server=server,
    num_rounds=50,
    local_epochs=5,
    client_fraction=1.0,
    prune_every=5
)

# EntraÃ®nement
history = edge_gnp.run()

# Visualisation
edge_gnp.plot_results(save_path='results.png')
```


<!-- ## ğŸ§ª RÃ©sultats ExpÃ©rimentaux

Les expÃ©riences montrent:

1. **RÃ©duction de communication:** 20-50% avec taux d'Ã©lagage Ï=0.3
2. **PrÃ©servation de performance:** â‰¥90% de l'accuracy originale
3. **ComplexitÃ©:** Greedy est le plus rapide, Spectral le plus prÃ©cis

### Exemple de RÃ©sultats

```
Taux d'Ã©lagage: 30%
- ArÃªtes conservÃ©es: 70%
- Test Accuracy: 0.89 (vs 0.92 sans Ã©lagage)
- RÃ©duction communication: 35%
- Temps convergence: +10%
```

## ğŸ“Š MÃ©triques Ã‰valuÃ©es

- **Accuracy**: PrÃ©cision de classification
- **Communication Cost**: Nombre de paramÃ¨tres + arÃªtes transmis
- **Clustering Coefficient**: PrÃ©servation de la structure locale
- **Spectral Distance**: ||Î»(L) - Î»(LÌƒ)||â‚‚
- **Modularity**: QualitÃ© de la structure communautaire
- **Training Time**: Temps par round -->

## ğŸ” Analyse de ComplexitÃ©

| Algorithme | ComplexitÃ© Temps | ComplexitÃ© Espace |
|------------|------------------|-------------------|
| Greedy Edge Pruning | O(ÏmÂ² + Ïmn) | O(n + m) |
| Spectral Sparsification | O(mknÂ²) | O(nÂ²) |
| Community-Aware | O(m log m) | O(n + m) |
| Edge-GNP (par round) | O(NÂ·T_prune + NÂ·EÂ·T_GNN) | O(Np) |

oÃ¹:
- **Ï**: Taux d'Ã©lagage
- **m**: Nombre d'arÃªtes
- **n**: Nombre de nÅ“uds
- **k**: Nombre de valeurs propres
- **N**: Nombre de clients
- **E**: Ã‰poques locales
- **p**: Nombre de paramÃ¨tres du modÃ¨le


## ğŸ› ï¸ DÃ©veloppement Futur

- [ ] Ã‰lagage dynamique adaptatif
- [ ] Pruning diffÃ©rentiel pour confidentialitÃ©
- [ ] Support pour graphes hÃ©tÃ©rogÃ¨nes
- [ ] Optimisation multi-objectifs
- [ ] Compression des paramÃ¨tres GNN
- [ ] Benchmark sur datasets rÃ©els (Cora, CiteSeer, PubMed)

## ğŸ“§ Contact

Pour toute question sur le projet:
- **Email:** [Joshua.YUN-PEI@um6p.ma]
- **GitHub:** https://github.com/Yunpei24/Edge-GNP.git

## ğŸ“œ Licence

Ce projet est dÃ©veloppÃ© dans un cadre acadÃ©mique pour le cours "Algorithmics, Complexity, and Graph Algorithms".

## ğŸ™ Remerciements

- Professeur du cours Professeur Emerite Michel Habib pour les orientations
- CommunautÃ© PyTorch Geometric pour les outils GNN
- Travaux de recherche de McMahan et al. (FedAvg), Kipf & Welling (GCN)

---

**Note:** Ce projet est un prototype de recherche. Pour une utilisation en production, des optimisations supplÃ©mentaires et des tests de robustesse sont nÃ©cessaires.
